{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ha-pu/data_course/blob/Google_Colab/5-llms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaiDKLvmk0jS"
      },
      "source": [
        "+ title: Large Language Models (LLMs)\n",
        "+ author: Harald Puhr\n",
        "+ date: April 21, 2025\n",
        "\n",
        "# Load packages and data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "install.packages(c(\"ellmer\", \"tidyverse\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "library(ellmer)\n",
        "library(tidyverse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate dummy data\n",
        "\n",
        "This code processes a list of customer reviews for a bike product. It creates a\n",
        "tibble (data frame) with the reviews and assigns a unique Review_ID to each\n",
        "review. Variables:\n",
        "\n",
        "+ reviews: A character vector containing customer reviews for a bike product.\n",
        "+ data: A tibble containing the customer reviews and their corresponding Review_IDs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "reviews = c(\n",
        "    \"My daughter absolutely loves this bike! Easy to assemble and sturdy.\",\n",
        "    \"The bike is well-made and looks great, but it arrived with a scratch.\",\n",
        "    \"Perfect size for my 5-year-old son. He rides it every day!\",\n",
        "    \"The training wheels are a bit flimsy, but otherwise it's a good bike.\",\n",
        "    \"Great value for the price. Assembly was simple and instructions were clear.\",\n",
        "    \"My son outgrew his old bike, and this was a perfect upgrade. Highly recommend.\",\n",
        "    \"Poor quality materials. The chain fell off after one week of use.\",\n",
        "    \"We had trouble with the brakes at first, but customer service was very helpful.\",\n",
        "    \"Fantastic bike! My daughter loves the color and design.\",\n",
        "    \"The seat could be more comfortable, but it's a nice bike overall.\"\n",
        ")\n",
        "\n",
        "data = tibble(Customer_Review = reviews) %>%\n",
        "  mutate(Review_ID = row_number())\n",
        "\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize LLM\n",
        "\n",
        "Set the OpenAI API key as a environment variable for authentication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "Sys.setenv(\n",
        "  OPENAI_API_KEY = \"XXX\" # Replace with your OpenAI API key.\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "base_model <- \"gpt-4.1-nano\" # Replace with your preferred model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test LLM\n",
        "\n",
        "This code initializes a chat session with the OpenAI GPT-4.1-nano model and sends\n",
        "a query to the model asking \"Who created R?\". The response from the model is\n",
        "not printed to the console (echo = FALSE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "chat <- chat_openai(model = base_model)\n",
        ". <- chat$chat(\"Who created R?\", echo = FALSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show the chat including the query and response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "chat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function call `token_usage()` is used to track or display the usage of\n",
        "tokens by model. This is important for billing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "token_usage()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create a function to query the LLM\n",
        "\n",
        "## Function: Get response from OpenAI chat model\n",
        "\n",
        "This function facilitates interaction with the OpenAI chat model by generating\n",
        "a response based on the provided system and user prompts.\n",
        "\n",
        "### Parameters:\n",
        "\n",
        "+ **system**: A character string that serves as the system prompt to initialize\n",
        "  the chat model.\n",
        "+ **user**: A character string that represents the user prompt to which the chat\n",
        "  model will generate a response.\n",
        "\n",
        "### Returns:\n",
        "\n",
        "A character string containing the response generated by the chat model.\n",
        "\n",
        "### Examples:\n",
        "\n",
        "```{r}\n",
        "# system_prompt <- \"You are a helpful assistant.\"\n",
        "# user_prompt <- \"What is the weather like today?\"\n",
        "# response <- get_response(system_prompt, user_prompt)\n",
        "# print(response)\n",
        "```\n",
        "\n",
        "### Define function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "get_response <- function(system, user) {\n",
        "  chat <- chat_openai(\n",
        "    model = base_model,\n",
        "    system_prompt = system,\n",
        "    echo = \"none\"\n",
        "  )\n",
        "  out <- chat$chat(user)\n",
        "  return(out)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification of customer reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "system_prompt <- \"You are a classifier for customer reviews. Review each\n",
        "customer review whether it is negative or positive. Return only a number between\n",
        "1 (negative) and 5 (positive).\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Apply classification\n",
        "\n",
        "This line of code calls the `get_response` function with two arguments:\n",
        "\n",
        "+ `system_prompt`: A variable that likely contains a prompt or instruction\n",
        "  for the system.\n",
        "+ `data$Customer_Review[[1]]`: The first element of the `Customer_Review`\n",
        "  column in the `data` dataframe.\n",
        "\n",
        "The function is expected to generate a response based on the provided system\n",
        "prompt and customer review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "get_response(system_prompt, data$Customer_Review[[1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This code performs the following operations on the 'data' dataframe:\n",
        "\n",
        "+ Creates a new column 'Classification' by applying the 'get_response'\n",
        "  function to each element in the 'Customer_Review' column. The 'get_response'\n",
        "  function is called with 'system_prompt' and each 'Customer_Review' as\n",
        "  arguments.\n",
        "+ Expands the 'Classification' column if it contains nested data.\n",
        "+ Converts the 'Classification' column to numeric type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "data1 <- data %>%\n",
        "  mutate(Classification = map(Customer_Review, ~ get_response(system_prompt, .))) %>%\n",
        "  unnest(Classification) %>%\n",
        "  mutate(Classification = as.numeric(Classification))\n",
        "\n",
        "data1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This code creates a histogram using ggplot2 in R. It takes the data frame\n",
        "'data1' and plots a histogram of the 'Classification' variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "data1 %>%\n",
        "  ggplot() +\n",
        "  geom_histogram(aes(x = Classification), bins = 5) +\n",
        "  labs(x = \"Classification\", y = \"Frequency\") +\n",
        "  ggtitle(\"Histogram of Classification\") +\n",
        "  theme_bw()\n",
        "\n",
        "filter(data1, Classification <= 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Re-run classification to test stability of results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "data2 <- data1 %>%\n",
        "  mutate(Classification2 = map(Customer_Review, ~ get_response(system_prompt, .))) %>%\n",
        "  unnest(Classification2) %>%\n",
        "  mutate(Classification2 = as.numeric(Classification2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This code creates a scatter plot using ggplot2 in R. It visualizes the\n",
        "relationship between two variables: Classification and Classification2 from\n",
        "the data2 dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "data2 %>%\n",
        "  ggplot() +\n",
        "  geom_point(aes(x = Classification, y = Classification2)) +\n",
        "  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") +\n",
        "  labs(x = \"Classification\", y = \"Classification2\") +\n",
        "  ggtitle(\"Classification vs. Classification2\") +\n",
        "  theme_bw()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Working with structured data in ellmer\n",
        "\n",
        "This code defines an object `type_score`. The object includes a system prompt\n",
        "and a type definition for an output variable `customer_score`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "type_score <- type_object(\n",
        "  \"Classify the customer review whether it is negative (1) or positive (5).\",\n",
        "  customer_score = type_number(\"Customer reviewer classification, ranging from 1 to 5.\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function: Get numeric from OpenAI chat model\n",
        "\n",
        "This function interacts with the OpenAI chat model to get a response based on\n",
        "the provided system and user prompts. The `type_score` object is used to force\n",
        "the LLM to generate a numeric output for the customer score.\n",
        "\n",
        "### Parameters:\n",
        "\n",
        "+ **system**: A string representing the system prompt to guide the chat model.\n",
        "+ **user**: A string representing the user input to be processed by the chat model.\n",
        "\n",
        "### Returns:\n",
        "\n",
        "A numeric value representing the customer score extracted from the chat model's response.\n",
        "\n",
        "### Examples:\n",
        "\n",
        "```{r}\n",
        "# system_prompt <- \"You are a helpful assistant.\"\n",
        "# user_input <- \"How can I improve my coding skills?\"\n",
        "# score <- get_response2(system_prompt, user_input)\n",
        "# print(score)\n",
        "```\n",
        "\n",
        "### Define function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "get_response2 <- function(system, user) {\n",
        "  chat <- chat_openai(\n",
        "    model = base_model,\n",
        "    system_prompt = system,\n",
        "    echo = \"none\"\n",
        "  )\n",
        "  out <- chat$extract_data(user, type = type_score)\n",
        "  return(out$customer_score)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This code calls the `get_response2` function with two arguments:\n",
        "\n",
        "+ `system_prompt`: A variable that likely contains a prompt or instruction\n",
        "  for the system.\n",
        "+ `data$Customer_Review[[1]]`: The first element of the `Customer_Review`\n",
        "  column in the `data` dataframe.\n",
        "  \n",
        "The function is expected to generate a response based on the provided system\n",
        "prompt and customer review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "get_response2(system_prompt, data$Customer_Review[[1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Force output to be numeric\n",
        "\n",
        "This line of code creates a new dataframe `data3` by mutating the existing\n",
        "dataframe `data1`. It adds a new column `Classification3` which is generated\n",
        "by applying the `get_response2` function to each element in the\n",
        "`Customer_Review` column of `data1`. The `get_response2` function is called\n",
        "with `system_prompt` and the current element of `Customer_Review` as arguments.\n",
        "Because `get_response2` uses the `type_score`object to structure the ouput, we\n",
        "can use the `map_int` function to create a column of integers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "data3 <- mutate(data1, Classification3 = map_int(Customer_Review, ~ get_response2(system_prompt, .)))\n",
        "\n",
        "data3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function: Get summary output from OpenAI chat model\n",
        "\n",
        "This code defines an object `type_summary`. The object includes a system\n",
        "prompt and a type definition for an output variable `issue`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "type_summary <- type_object(\n",
        "  \"Summarize the main issue mentioned in the review.\",\n",
        "  issue = type_string(\"Main problem mentioned.\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function interacts with the OpenAI chat model to generate a response\n",
        "based on the provided system and user prompts. The `type_summary` object is\n",
        "used to ensure the LLM generates a character output summarizing the main issue\n",
        "mentioned in the review.\n",
        "\n",
        "### Parameters:\n",
        "\n",
        "+ `system`: A character string representing the system prompt to guide the\n",
        "  chat model.\n",
        "+ `user`: A character string representing the user's input or query.\n",
        "\n",
        "### Returns:\n",
        "\n",
        "A character string containing the extracted data from the chat model's\n",
        "response, specifically the issue summary.\n",
        "\n",
        "### Examples:\n",
        "\n",
        "```{r}\n",
        "# system_prompt <- \"You are a helpful assistant.\"\n",
        "# user_input <- \"What is the weather like today?\"\n",
        "# get_response3(system_prompt, user_input)\n",
        "```\n",
        "\n",
        "### Define function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "get_response3 <- function(system, user) {\n",
        "  chat <- chat_openai(\n",
        "    model = base_model,\n",
        "    system_prompt = system,\n",
        "    echo = \"none\"\n",
        "  )\n",
        "  out <- chat$extract_data(user, type = type_summary)\n",
        "  return(out$issue)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This line of code calls the `get_response3` function with two arguments:\n",
        "\n",
        "1. `system_prompt`: A variable that likely contains a prompt or instruction\n",
        "  for the system.\n",
        "2. `data$Customer_Review[[1]]`: The first element of the `Customer_Review`\n",
        "  column in the `data` dataframe.\n",
        "\n",
        "The function is expected to generate a response based on the provided system\n",
        "prompt and customer review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "get_response3(system_prompt, data$Customer_Review[[1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This code filters the data1 dataframe to include only rows where the\n",
        "'Classification' column is less than or equal to 3. It then creates a new\n",
        "column 'Issue' in the resulting dataframe by applying the 'get_response3'\n",
        "function to each element in the 'Customer_Review' column. The 'get_response3'\n",
        "function takes 'system_prompt' and the customer review as arguments. Because\n",
        "`get_response3` uses the `type_summary`object to structure the ouput, we\n",
        "can use the `map_chr` function to create a column of characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "data4 <- data1 %>%\n",
        "  filter(Classification <= 3) %>%\n",
        "  mutate(Issue = map_chr(Customer_Review, ~ get_response3(system_prompt, .)))\n",
        "\n",
        "data4\n",
        "data4$Issue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercises\n",
        "\n",
        "+ **Modify the classification system prompt**: Change the system prompt in the\n",
        "  `type_score` object to classify reviews on a scale of 1 to 10 instead of 1 to\n",
        "  5. Update the `get_response` function accordingly.\n",
        "+ **Add a new feature**: Create a new feature in the `data` dataframe that\n",
        "  indicates whether the review is generally positive or negative. Compare this\n",
        "  feature to the initial results.\n",
        "+ **Visualize the results**: Create a visual analysis that compares the results\n",
        "  from the previous step to your intitial results.\n",
        "+ **Explore different models**: Experiment with different OpenAI models\n",
        "  (e.g., `gpt-4.1`, `gpt-4.1-mini`, `gpt-4o-mini`) and compare their performance\n",
        "  in classifying the reviews. Document any differences you observe.\n",
        "+ **Multi-class classification**: Extend the classification task to include more\n",
        "  than two classes (e.g., very negative, negative, neutral, positive, very\n",
        "  positive) and evaluate the model's performance on this multi-class problem.\n",
        "+ **Ethical considerations**: Discuss the ethical implications of using LLMs for\n",
        "  sentiment analysis and classification, including potential biases in the model\n",
        "  and how to mitigate them.\n",
        "+ **Real-world application**: Discuss other real-world applications for text\n",
        "  classification with LLMs other than feedback classification. What\n",
        "  considerations would you need to take into account when applying LLMs in these\n",
        "  scenarios?\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN32YnVDkBH6+AOyEXOXkIM",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
