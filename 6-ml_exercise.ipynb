{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ha-pu/data_course/blob/AOM25/6-ml_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaiDKLvmk0jS"
      },
      "source": [
        "+ title: Machine Learning Exercises\n",
        "+ author: Harald Puhr\n",
        "+ date: July 23, 2025\n",
        "\n",
        "[Data Source](https://github.com/ha-pu/data_files#subsidiary-income-dataset)\n",
        "\n",
        "# Load packages and data\n",
        "\n",
        "## Install and load packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "install.packages(c(\"caret\", \"gbm\", \"glmnet\", \"randomForest\", \"tidyverse\", \"xgboost\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "library(caret)\n",
        "library(tidyverse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "set.seed(123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "fdi_df <- read_csv(\n",
        "    \"https://raw.githubusercontent.com/ha-pu/data_files/refs/heads/main/5-subsidiary_income.csv\",\n",
        "    col_types = cols(\"i\", \"f\", \"i\", \"i\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"f\", \"f\", \"f\")\n",
        ") %>%\n",
        "    drop_na()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preparing our data\n",
        "\n",
        "The implementations of most machine learning algorithms in R have very specific\n",
        "requirements regarding the coding of input data. This means we have to take\n",
        "more steps to prepare the data than when working with simple regressions.\n",
        "\n",
        "## Inspect data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "slice_head(fdi_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "glimpse(fdi_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "summary(fdi_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare the data\n",
        "\n",
        "\n",
        "## Lagging predictors\n",
        "\n",
        "We need need to create predictions on the data from the previous years, so we\n",
        "have to lag the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "lagged_df <- fdi_df %>%\n",
        "    arrange(Year) %>%\n",
        "    mutate(\n",
        "        across(.cols = !contains(\"_L\"), .fns = list(L1 = ~ lag(., n = 1))),\n",
        "        across(.cols = !contains(\"_L\"), .fns = list(L2 = ~ lag(., n = 2))),\n",
        "        .by = c(DomesticId, ForeignId)\n",
        "    ) %>%\n",
        "    select(\n",
        "        !contains(\"Year_L\") &\n",
        "            !contains(\"CountryCode_L\") &\n",
        "            !contains(\"DomesticId_L\") &\n",
        "            !contains(\"ForeignId_L\")\n",
        "    ) %>%\n",
        "    replace_na(list(Income = 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Remove features\n",
        "\n",
        "Now we need to remove the features we cannot know in advance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "data_df <- select(\n",
        "    lagged_df,\n",
        "    -c(\n",
        "        \"NumFeature1\", \"NumFeature2\", \"NumFeature3\", \"NumFeature4\",\n",
        "        \"NumFeature5\", \"NumFeature6\", \"FactorFeature1\", \"FactorFeature2\",\n",
        "        \"FactorFeature3\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And finally, we also remove all observations for which we do not have any\n",
        "information and drop the Id columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "data_df$na_check <- rowSums(is.na(data_df[6:ncol(data_df)]))\n",
        "\n",
        "data_df <- data_df %>%\n",
        "    filter(na_check != 30) %>%\n",
        "    select(-c(na_check, Year, CountryCode, DomesticId, ForeignId)) %>%\n",
        "    as.data.frame()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Take a look at the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "glimpse(data_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modeling setup\n",
        "\n",
        "## Transform categorical predictors into dummy variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "dummyModel <- dummyVars(Income ~ ., data_df, fullRank = FALSE)\n",
        "\n",
        "data_df <- data_df %>%\n",
        "    select(Income) %>%\n",
        "    bind_cols(data.frame(predict(dummyModel, newdata = data_df)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define dependent and independent variables\n",
        "\n",
        "Let's define which column is our DV and which are the IVs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "label <- \"Income\"\n",
        "predictors <- setdiff(names(data_df), label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train-test split\n",
        "\n",
        "Now we have to create a train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "train_index <- createDataPartition(data_df$Income, p = 0.8, list = FALSE)\n",
        "\n",
        "train_df <- data_df[train_index, ]\n",
        "\n",
        "test_df <- data_df[-train_index, ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing\n",
        "\n",
        "Now we can decide on how to preprocess our data. Since we have a lot of dummies,\n",
        "it is likely helpful to drop low variance columns. Also we have many missing \n",
        "values so we should use some imputation methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "pre_process <- (method <- c(\"medianImpute\", \"nzv\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define training parameters\n",
        "\n",
        "For the next step we have to decide on a train control method.\n",
        "To keep things consistent we want to manually define our folds first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "testFolds <- createFolds(train_df[, label], k = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set training control to cross validation and adaptive tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "train_control <- trainControl(\n",
        "    method = \"cv\",\n",
        "    index = testFolds,\n",
        "    verboseIter = TRUE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model training\n",
        "\n",
        "First let's train a gradient boosted tree model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_xgbTree <- train(\n",
        "    x = train_df[, predictors],\n",
        "    y = train_df[, label],\n",
        "    method = \"xgbTree\",\n",
        "    tuneLength = 2,\n",
        "    trControl = train_control,\n",
        "    preProcess = pre_process\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing\n",
        "\n",
        "As the last step we need to see how well our models are doing.\n",
        "First we need to use the model to create predictions for our test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "test_df$pred_xgbTree <- predict(model_xgbTree, newdata = test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets plot and see how well we do:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "test_df %>%\n",
        "    ggplot() +\n",
        "    geom_point(aes(x = Income, y = pred_xgbTree)) +\n",
        "    geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
        "    geom_abline(slope = cor(test_df$Income, test_df$pred_xgbTree), intercept = 0, color = \"blue\") +\n",
        "    labs(\n",
        "        x = \"Actual\",\n",
        "        y = \"Predicted\",\n",
        "        title = paste(\"Correlation: \", round(cor(test_df$Income, test_df$pred_xgbTree), 3), sep = \"\")\n",
        "    ) +\n",
        "    theme_bw()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "# Exercise\n",
        "\n",
        "Use the code from `4-machine_learning.rmd` to train other models on the same\n",
        "data. Compare how your models are doing vis-Ã -vis the `xgbTree` model.\n",
        "\n",
        "You can find a summary of all models included in the `caret` package\n",
        "[here](https://topepo.github.io/caret/available-models.html).\n",
        "\n",
        "**Binder is limited in terms of resources! Some models might take some time to run.**\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN32YnVDkBH6+AOyEXOXkIM",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
