{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ha-pu/data_course/blob/Google_Colab/4-machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaiDKLvmk0jS"
      },
      "source": [
        "+ title: Machine Learning\n",
        "+ author: Harald Puhr\n",
        "+ date: April 8, 2025\n",
        "\n",
        "[Data Source](https://github.com/ha-pu/data_files#repurchase-likelihood-dataset)\n",
        "\n",
        "# Load packages and data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "install.packages(c(\"caret\", \"caretEnsemble\", \"gbm\", \"glmnet\", \"randomforest\", \"tidyverse\", \"xgboost\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "library(caret)\n",
        "library(caretEnsemble)\n",
        "library(tidyverse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setting a seed is important for reproducibility. It ensures that the random\n",
        "processes in your code yield the same results each time you run it. This is\n",
        "particularly crucial in machine learning, where randomness can significantly\n",
        "affect model training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "set.seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "df <- read_csv(\"https://raw.githubusercontent.com/ha-pu/data_files/refs/heads/main/4-repurchase_likelihood.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preparing our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "glimpse(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recode variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "df <- df %>% \n",
        "  mutate(\n",
        "    repurchase = factor(repurchase),\n",
        "    customer_sex = factor(customer_sex),\n",
        "    customer_tier = factor(customer_tier)\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Drop columns which do not contain relevant information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "df <- select(df, -customer_id, -customer_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transform categorical predictors into dummy variables\n",
        "\n",
        "R stores categorial data as factors (e.g., variable = A, B, A, A, B). For\n",
        "machine learning, we transform them into separate columns:\n",
        "(variable.A = 1, 0, 1, 1, 0; variable.B = 0, 1, 0, 0, 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "dummyModel <- dummyVars(repurchase ~ ., df, fullRank = TRUE)\n",
        "\n",
        "df <- predict(dummyModel, newdata = df) %>%\n",
        "  as_tibble() %>%\n",
        "  mutate(repurchase = df$repurchase)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Designate he column names of our outcome and predictor variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "label <- \"repurchase\"\n",
        "predictors <- names(df)[!(names(df) %in% label)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Splitting the data into training and test sets\n",
        "\n",
        "If we test the model on the same data as we train it, we can only verify how\n",
        "well the algorithm fits the data it has seen during training. This is not a good\n",
        "measure of accuracy. We want to know how well it fits data it has **not** seen\n",
        "in training. Therefore, we put part of the data aside for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "train_idx <- sample(seq(nrow(df)), size = nrow(df) * 0.8)\n",
        "train_df <- slice(df, train_idx)\n",
        "test_df <- slice(df, -train_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pre-processing the data\n",
        "\n",
        "## Change data type of the label variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "y_train <- train_df[,label][[1]]\n",
        "y_test <- test_df[,label][[1]]\n",
        "\n",
        "# Ensure levels of y_train are valid R variable names\n",
        "levels(y_train) <- make.names(levels(y_train))\n",
        "levels(y_test) <- make.names(levels(y_test))\n",
        "\n",
        "head(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Avoid multicollinearity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "findCorrelation(cor(train_df[,predictors]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check for missing values and use median imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "summary(train_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Machine learning algorithms do not handle missing data well. We, therefore,\n",
        "impute missing data with the sample median."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "preproc_par <- preProcess(train_df[,predictors], method = c(\"medianImpute\"))\n",
        "train_df[,predictors] <- predict(preproc_par, train_df[,predictors])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scale and center the data\n",
        "\n",
        "Machine learning algorithms do not handle differences in the scaling of\n",
        "variables well. This is an issue if we use variables that have different data\n",
        "ranges in the same model (e.g., Total GDP and GPD/cpaita). To solve the issue,\n",
        "we standardize numeric predictors to *mean = 0* and *SD = 1*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "preproc_par <- preProcess(train_df[,predictors], method=c(\"center\", \"scale\"))\n",
        "train_df[,predictors] <- predict(preproc_par, train_df[,predictors])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "preprocPar <- preProcess(test_df[,predictors], method=c(\"center\", \"scale\", \"medianImpute\"))\n",
        "test_df[,predictors] <- predict(preprocPar, test_df[,predictors])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model training, validation, and testing\n",
        "\n",
        "## Training\n",
        "\n",
        "We use 5-fold cross-validation (CV) for training. CV means that the model is\n",
        "train on 4/5 of the data and validates it on the remaining 1/5 of the data. This\n",
        "process is repeated 4 times (once on every fold). Then, we take the average of\n",
        "these 5 evaluations to get the final evaluation of the respective training step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "quickTrain <- trainControl(method = \"cv\", number = 5)\n",
        "\n",
        "model_rf <- train(x = train_df[,predictors], y = y_train, method = \"rf\", trControl = quickTrain)\n",
        "\n",
        "model_glmnet <- train(x = train_df[,predictors], y = y_train, method = \"glmnet\", trControl = quickTrain)\n",
        "\n",
        "model_nnet <- train(x = train_df[,predictors], y = y_train, method = \"nnet\", trControl = quickTrain)\n",
        "\n",
        "model_xgbTree <- train(x = train_df[,predictors], y = y_train, method = \"xgbTree\", trControl = quickTrain)\n",
        "\n",
        "model_xgbLinear <- train(x = train_df[,predictors], y = y_train, method = \"xgbLinear\", trControl = quickTrain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_glmnet %>%\n",
        "  ggplot(highlight = TRUE) +\n",
        "  theme_bw()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_nnet %>%\n",
        "  ggplot(highlight = TRUE) +\n",
        "  theme_bw()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "comparison_alg <- tibble(\n",
        "  Model = c(\"rf\",\"glmnet\",\"nnet\",\"xgbTree\",\"xgbLinear\"),\n",
        "  Accuracy_base = c(\n",
        "    max(model_rf$results$Accuracy), max(model_glmnet$results$Accuracy),\n",
        "    max(model_nnet$results$Accuracy), max(model_xgbTree$results$Accuracy),\n",
        "    max(model_xgbLinear$results$Accuracy))\n",
        ")\n",
        "\n",
        "comparison_alg %>%\n",
        "  ggplot() +\n",
        "  geom_bar(aes(x = Model, y = Accuracy_base), stat = \"identity\") +\n",
        "  geom_hline(aes(yintercept = max(Accuracy_base)), linetype = \"dashed\", color = \"darkred\") +\n",
        "  scale_y_continuous(limits = c(0.0, 0.9)) +\n",
        "  theme_bw()\n",
        "\n",
        "comparison_alg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Additional validation methods\n",
        "\n",
        "We repeat the analysis with 10-fold cross-validation and bootstraping. In\n",
        "bootstraping, we create subsamples of the data by sampling with replacement.\n",
        "This means that some observations may be included multiple times in a subsample,\n",
        "while others may not be included at all. The model is trained on these\n",
        "subsamples, and the process is repeated multiple times to obtain a more robust\n",
        "estimate of the model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Cross validation training method\n",
        "crossValidation <- trainControl(method = \"cv\", number = 10)\n",
        "\n",
        "# Boot strapping training method\n",
        "bootstraping <- trainControl(method = \"boot\")\n",
        "\n",
        "# Apply both methods to a random forest model\n",
        "model_cv <- train(x = train_df[,predictors], y = y_train, method = \"rf\", trControl = crossValidation)\n",
        "model_boot <- train(x = train_df[,predictors], y = y_train, method = \"rf\", trControl = bootstraping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "comparison_val <- tibble(\n",
        "  Model = c(\"cv5\", \"cv10\",\"boot\"),\n",
        "  Accuracy_base = c(\n",
        "    max(model_rf$results$Accuracy), max(model_cv$results$Accuracy),\n",
        "    max(model_boot$results$Accuracy)\n",
        "  )\n",
        ")\n",
        "\n",
        "comparison_val %>%\n",
        "  ggplot() +\n",
        "  geom_bar(aes(x = Model, y = Accuracy_base), stat = \"identity\") +\n",
        "  geom_hline(aes(yintercept = max(Accuracy_base)), linetype = \"dashed\", color = \"darkred\") +\n",
        "  scale_y_continuous(limits = c(0.0, 0.9)) +\n",
        "  theme_bw()\n",
        "\n",
        "comparison_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model tuning\n",
        "\n",
        "Through tuning, we can optimize the hyperparameters of our model to improve its\n",
        "learning behavor. Hyperparameters are parameters that are set before the\n",
        "learning process begins. They are not learned from the data but are instead\n",
        "specified by the user before training the model. Examples include\n",
        "the learning rate, the number of trees in a random forest, the number of hidden\n",
        "layers in a neural network, and the regularization strength in a linear model.\n",
        "\n",
        "We test three approaches to tuning:\n",
        "\n",
        "* Grid search: Systematically evaluates a predefined grid of hyperparameter combinations.\n",
        "* Random search: Randomly samples parameter combinations from the parameter space.\n",
        "* Adaptive search: Starts with a random search (or grid), but learns from\n",
        "  performance during tuning and stops testing unpromising combinations early."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Grid tuning\n",
        "gridTune <- trainControl(method = \"cv\", search = \"grid\")\n",
        "\n",
        "# Random search tuning method:\n",
        "randomTune <- trainControl(method = \"cv\", search = \"random\")\n",
        "\n",
        "# Adaptive search tuning method:\n",
        "adaptiveTune <- trainControl(\n",
        "  method = \"adaptive_cv\",\n",
        "  adaptive = list(min = 2, alpha = 0.05, method = \"gls\", complete = TRUE),\n",
        "  search = \"random\"\n",
        "  )\n",
        "\n",
        "# Apply all three methods to a glmnet model\n",
        "model_grid <- train(\n",
        "  x = train_df[,predictors], y = y_train, method = \"glmnet\",\n",
        "  trControl = gridTune, tuneLength = 5\n",
        "  )\n",
        "model_random <- train(\n",
        "  x = train_df[,predictors], y = y_train, method = \"glmnet\",\n",
        "  trControl = randomTune, tuneLength = 25\n",
        "  )\n",
        "model_adaptive <- train(\n",
        "  x = train_df[,predictors], y = y_train, method = \"glmnet\",\n",
        "  trControl = adaptiveTune, tuneLength = 25\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "comparison_tune <- tibble(\n",
        "  Model = c(\"cv5\", \"grid\", \"random\", \"adaptive\"),\n",
        "  Accuracy_base = c(\n",
        "    max(model_glmnet$results$Accuracy), max(model_grid$results$Accuracy),\n",
        "    max(model_random$results$Accuracy), max(model_adaptive$results$Accuracy)\n",
        "  )\n",
        ")\n",
        "\n",
        "comparison_tune %>%\n",
        "  ggplot() +\n",
        "  geom_bar(aes(x = Model, y = Accuracy_base), stat = \"identity\") +\n",
        "  geom_hline(aes(yintercept = max(Accuracy_base)), linetype = \"dashed\", color = \"darkred\") +\n",
        "  scale_y_continuous(limits = c(0.0, 0.9)) +\n",
        "  theme_bw()\n",
        "\n",
        "comparison_tune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "comparison_all <- bind_rows(comparison_alg, comparison_val, comparison_tune) %>%\n",
        "  filter(Model != \"cv5\")\n",
        "\n",
        "det_OOS_accuracy <- function(model){\n",
        "  confusionMatrix(predict(model, test_df), y_test)$overall[[1]]\n",
        "}\n",
        "\n",
        "all_model_list <- list(\n",
        "  model_rf, model_glmnet, model_nnet, model_xgbTree,\n",
        "  model_xgbLinear, model_cv, model_boot, model_grid,\n",
        "  model_random, model_adaptive\n",
        ")\n",
        "\n",
        "comparison_all <- mutate(\n",
        "  comparison_all,\n",
        "  OOS_Acc = map_dbl(all_model_list, det_OOS_accuracy)\n",
        ")\n",
        "\n",
        "comparison_all %>%\n",
        "  pivot_longer(\n",
        "    cols = c(Accuracy_base, OOS_Acc),\n",
        "    names_to = \"Base\",\n",
        "    values_to = \"Accuracy\"\n",
        "  ) %>%\n",
        "  ggplot() +\n",
        "  geom_line(aes(x = Model, y = Accuracy, color = Base, group = Base)) +\n",
        "  geom_point(aes(x = Model, y = Accuracy, color = Base)) +\n",
        "  geom_hline(aes(yintercept = max(comparison_all$Accuracy_base)), colour = \"darkred\", linetype = \"dashed\") +\n",
        "  geom_hline(aes(yintercept = max(comparison_all$OOS_Acc)), colour = \"darkblue\", linetype = \"dashed\") +\n",
        "  scale_y_continuous(limits = c(0.0, 0.9)) +\n",
        "  theme_bw()\n",
        "\n",
        "arrange(comparison_all, desc(OOS_Acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variable importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "varImp(model_xgbTree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "plot(varImp(model_xgbTree), main = \"xgbTree\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "plot(varImp(model_nnet), main = \"nnet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "plot(varImp(model_glmnet), main = \"glmnet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ensemble learning\n",
        "\n",
        "Ensemble learning is a machine learning technique that combines predictions from\n",
        "multiple models to improve accuracy, robustness, and generalization. The idea is\n",
        "simple but powerful: A group of diverse models working together is usually\n",
        "better than any single one.\n",
        "\n",
        "There are mulitpe ways to combine models:\n",
        "* Bagging: Build many models on different random subsets of the data and combine\n",
        "  them via averaging (regression) or voting (classification).\n",
        "* Boosting: Build models sequentially, where each model learns from the errors\n",
        "  of the previous and combine them with weighted averaging.\n",
        "* Stacking: Build several base models and train a meta-model on their predictions.\n",
        "\n",
        "We first define a list of models and apply them to the same folds of our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "algoList <- c(\"rf\", \"glmnet\", \"nnet\", \"xgbTree\", \"xgbLinear\", \"svmLinear2\")\n",
        "\n",
        "stack_index = createFolds(y_train, k = 5) # We want to fix our index for comparison and validity\n",
        "\n",
        "listControl <- trainControl(\n",
        "  method = \"cv\", number = 5, \n",
        "  classProbs = TRUE, # We need to predict probabilities not 0 or 1 (more info)\n",
        "  savePredictions = TRUE, # necessary for stack model later\n",
        "  index = stack_index\n",
        ")\n",
        "\n",
        "models <- caretList(\n",
        "  x = train_df[,predictors], y = y_train, trControl = listControl,\n",
        "  methodList = algoList\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "results <- resamples(models)\n",
        "summary(results)\n",
        "modelCor(resamples(models))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Automatic model selection\n",
        "\n",
        "Next, we use a meta model to combine the predictions of the base models. The\n",
        "meta model can be a simple linear regression model or a more complex model like\n",
        "an extrame gradient boosting tree (xgbTree), a gradient boosting machine (gbm),\n",
        "or a simle logistic regression (glm)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "stackControl <- trainControl(\n",
        "  method = \"repeatedcv\", number = 10, repeats = 3, classProbs = TRUE,\n",
        "  index = stack_index\n",
        "  )\n",
        "\n",
        "stack_tree <- caretStack(models, method = \"xgbTree\", trControl = stackControl)\n",
        "\n",
        "stack_gbm <- caretStack(models, method = \"gbm\", trControl = stackControl)\n",
        "\n",
        "stack_glm <- caretStack(models, method = \"glm\", trControl = stackControl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "## Out-of-Sample Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "results <- tibble(\n",
        "  ensemble_tree = predict(stack_tree, test_df, type = \"prob\"),\n",
        "  ensemble_glm = predict(stack_glm, test_df, type = \"prob\"),\n",
        "  ensemble_gbm = predict(stack_gbm, test_df, type = \"prob\")\n",
        ")\n",
        "\n",
        "results <- predict(models, test_df) %>%\n",
        "  as_tibble() %>% \n",
        "  bind_cols(results)\n",
        "\n",
        "det_OOS_accuracy_probs <- function(model){\n",
        "  preds <- factor(model >= 0.5, labels = c(\"X0\", \"X1\"))\n",
        "  confusionMatrix(preds, y_test)$overall[[1]]\n",
        "}\n",
        "\n",
        "OOS_ACC <- results %>%\n",
        "  summarise(across(everything(), det_OOS_accuracy_probs))\n",
        "\n",
        "OOS_ACC\n",
        "\n",
        "OOS_ACC %>%\n",
        "  pivot_longer(cols = everything(), names_to = \"Model\", values_to = \"OOS_ACC\") %>%\n",
        "  ggplot() +\n",
        "  geom_bar(aes(x = Model, y = OOS_ACC), stat = \"identity\") + \n",
        "  geom_hline(aes(yintercept = max(OOS_ACC)), linetype = \"dashed\", color = \"darkred\") +\n",
        "  labs(\n",
        "    x = NULL\n",
        "  ) +\n",
        "  theme_bw() +\n",
        "  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN32YnVDkBH6+AOyEXOXkIM",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
